---
layout: project-page
title: Social Sensory Architectures
categories: project
slogan: Designed for gradations of touch and pressure sensitive input
description: A research project led by Prof. Sean Ahlquist at the University of Michigan to design technology-embedded multi-sensory environments for children with autism spectrum disorder.
folder: social_sensory_surface
cover: cover.jpg
title-cover: cover-title.jpg
links:
  - text: Project Website
    url: http://www.materialarchitectures.com/social-sensory/
tags: [project-feature, Tangible Interaction, Kinect, Computer Vision, OpenFrameworks, Unity3D, Projection Mapping]
---
<div class="video-container">
    <iframe src="https://www.youtube.com/embed/_-piBtnnZXw" frameborder="0" allowfullscreen></iframe>
</div>
<h2>Technology-embedded multi-sensory environments for children with autism spectrum disorder</h2>
Cotent is excertpted from the principal investigator, <a href="http://www.materialarchitectures.com/social-sensory/">Sean Ahlquist's website</a>:
<div class="quote message">
    <div class="message-body">
    <p>Social Sensory Architectures is an on-going research project led by Sean Ahlquist at the University of Michigan to design technology-embedded multi-sensory environments for children with autism spectrum disorder. The research involves the development of therapies which utilize the reinforcing capabilities of a multi-sensory experience for skill-building tasks related to fine/gross motor control and social interaction. Through the use of advanced textile design, sensing technology and bespoke software, complex textile landscapes are transformed into physically, visually and sonically interactive environments. The research was spurred initially by Ahlquist's observations of his daughter Ara, who has  autism along with specific issues such as non-verbal communication, sensory-seeking and hypotonia.</p>
    <p>The research integrates the fields of architecture, structural engineering, computer vision, human-computer interaction, psychiatry and kinesiology. Initial development took place, through a Research Through Making seed-funding grant from the University of Michigan - College of Architecture and Urban Planning, involving collaborators from the University of Michigan Departments of Electrical Engineering and Computer Science and the School of Music. Currently, the research involves collaboration with Costanza Colombi of the Department of Psychiatry, and Dale Ulrich sand Leach Ketcheson from the School of Kinesiology, supported by an interdisciplinary MCubed grant from the University of Michigan. Various prototypes are currently being piloted, through involvement with local centers working with children with autism, to measure the development of skills in grading of movement and identification of opportunities for social interactions.</p>
    <p>This research explores the interconnection between the domains of movement, social function and communication. Touch, a primary method for rudimentary nonverbal communication, involves the whole of the somatosensory system to produce the range and nuances for interpersonal interaction. Gestures and facial expressions function via feedback from stretch receptors of the skin and muscles in the hands and arms. Where abnormalities in the somatosensory system exist, often common for children with autism, there is a correlation with reduced abilities for social attention and impairments in nonverbal communication (Foss-Feig et al. 2012). Children who experience limitations in motor skills are shown to have fewer opportunities for social interaction with peers, correlating with lower levels of physical activity (MacDonald et al. 2014). In comparison with children having speech-language impairments or learning disabilities, those with autism are approximately 50% less likely to be invited to social activities and 450% more likely to never see friends (Shattuck et al. 2011).</p>
    </div>
</div>

<h2>Software and Sensing Technology</h2>
The software consists of two components: rendering and sensing. The rendering part is developed in Unity3D which embeds the visual and auditory interactivity through the use of projection. The rendering part is developed in Openframework and OpenCV with the depth information captured by Microsoft Kinect.

<div class="columns is-multiline">
    <div class="column is-half">
        <div class="card no-box-shadow">
            <div class="card-image">
                <figure class="image">
                    <img src="/assets/images/projects/social_sensory_surface/software.jpg">
                </figure>
            </div>
            <div class="card-content">
                Sensory[SOFTWARE] - Framework for the sensory architecture prototypes, interconnecting textile structures with the Microsoft Kinect and bespoke software programmed in Unity and OpenFrameworks.
            </div>
        </div>
    </div>
    <div class="column is-half">
        <div class="card no-box-shadow">
            <div class="card-image">
                <figure class="image">
                    <img src="/assets/images/projects/social_sensory_surface/structure.jpg">
                </figure>
            </div>
            <div class="card-content">
                Sensory[STRUCTURE} - Textile-hybrid structure formed of CNC knitted textiles interconnected with glass-fiber reinforced polymer (GFRP) rods.
            </div>
        </div>
    </div>
    <div class="column is-half">
        <div class="card no-box-shadow">
            <div class="card-image">
                <figure class="image">
                    <img src="/assets/images/projects/social_sensory_surface/playscape.jpg">
                </figure>
            </div>
            <div class="card-content">
                sensoryPLAYSCAPE (v1.0) textile hybrid prototype. 
            </div>
        </div>
    </div>
    <div class="column is-half">
        <div class="card no-box-shadow">
            <div class="card-image">
                <figure class="image">
                    <img src="/assets/images/projects/social_sensory_surface/stretchplay.jpg">
                </figure>
            </div>
            <div class="card-content">
                Touching the textile at key locations triggers animations for play across the structure of the sensoryPLAYSCAPE | stretchANIMATE prototype.
            </div>
        </div>
    </div>
    <div class="column is-half">
        <div class="card no-box-shadow">
            <div class="card-image">
                <figure class="image">
                    <img src="/assets/images/projects/social_sensory_surface/play.jpg">
                </figure>
            </div>
            <div class="card-content">
                An audience experienced the stretchANIMATE prototype in an exhibition.
            </div>
        </div>
    </div>
    <div class="column is-half">
        <div class="card no-box-shadow">
            <div class="card-image">
                <figure class="image">
                    <img src="/assets/images/projects/social_sensory_surface/swarm.jpg">
                </figure>
            </div>
            <div class="card-content">
                stretchSWARM software utilize with the sensoryPLAYSCAPE structure, where a long touch with the surface creates an attractor for a dynamic swarm of fish.
            </div>
        </div>
    </div>
</div>

